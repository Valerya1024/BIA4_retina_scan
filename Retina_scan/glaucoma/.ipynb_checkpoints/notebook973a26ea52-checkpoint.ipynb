{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook dives into creating a machine learning model to diagnose glaucoma.**\n",
    "\n",
    "\n",
    "***There has not been any solid dataset for glaucoma so I made one and created a model. Please check out my dataset if you are interested.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.reviewofoptometry.com/CMSImagesContent/2019/10/GlaucDiff1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Organizing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took the data from the sources, and seperated them into train and validation folders. Then from those folders, I sorted them into positive and negative cases. You can check out my jupyter notebook linked at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>ExpCDR</th>\n",
       "      <th>Eye</th>\n",
       "      <th>Set</th>\n",
       "      <th>Glaucoma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.jpg</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>OD</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.jpg</td>\n",
       "      <td>0.6953</td>\n",
       "      <td>OS</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.jpg</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>OS</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.jpg</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>OD</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.jpg</td>\n",
       "      <td>0.6138</td>\n",
       "      <td>OS</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename  ExpCDR Eye Set  Glaucoma\n",
       "0  001.jpg  0.7097  OD   A         0\n",
       "1  002.jpg  0.6953  OS   A         0\n",
       "2  003.jpg  0.9629  OS   A         0\n",
       "3  004.jpg  0.7246  OD   A         0\n",
       "4  005.jpg  0.6138  OS   A         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label = pd.read_csv('D:/Files/4/BIA4/ICA1/glaucoma/archive/glaucoma.csv')\n",
    "y_train = train_label['Glaucoma']\n",
    "train_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Looking at the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first tried some manual data augmentation and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG\n",
      "RGB\n",
      "(3072, 2048)\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "from PIL import Image\n",
    "# load the image\n",
    "image = Image.open('D:/Files/4/BIA4/ICA1/glaucoma/archive/Fundus_Train_Val_Data/Fundus_Scanes_Sorted/Validation/Glaucoma_Positive/613.jpg')\n",
    "# summarize some details about the image\n",
    "print(image.format)\n",
    "print(image.mode)\n",
    "print(image.size)\n",
    "# show the image\n",
    "image.show()\n",
    "pixels = asarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# global centering\n",
    "\n",
    "# calculate global mean\n",
    "mean = pixels.mean()\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "# global centering of pixels\n",
    "pixels = pixels - mean\n",
    "# confirm it had the desired effect\n",
    "mean = pixels.mean()\n",
    "print('Mean: %.3f' % mean)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "print(pixels)\n",
    "\n",
    "\n",
    "# example of pixel normalization\n",
    "# confirm pixel range is 0-255\n",
    "print('Data Type: %s' % pixels.dtype)\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "# convert from integers to floats\n",
    "pixels = pixels.astype('float32')\n",
    "# normalize to the range 0-1\n",
    "pixels /= 255.0\n",
    "mean = pixels.mean()\n",
    "print('pixel mean = ', mean)\n",
    "\n",
    "# confirm the normalization\n",
    "print('Min: %.3f, Max: %.3f' % (pixels.min(), pixels.max()))\n",
    "print(pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visulization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(image)\n",
    "ax0.axis('off')\n",
    "ax0.set_title('image')\n",
    "ax1.imshow(pixels)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "def imshow(image_RGB):\n",
    "  io.imshow(image_RGB)\n",
    "  io.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/kaggle/input/glaucoma-detection/Fundus_Train_Val_Data/Fundus_Scanes_Sorted/Train'\n",
    "\n",
    "TEST_DIR = '/kaggle/input/glaucoma-detection/Fundus_Train_Val_Data/Fundus_Scanes_Sorted/Validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ConvNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "  data_format=\"channels_last\",\n",
    "  rescale = 1. / 255\n",
    ")\n",
    "\n",
    "train_batches = train_generator.flow_from_directory(\n",
    "    batch_size=32,\n",
    "    directory='./dataset/train',\n",
    "    target_size=(256, 256),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = ImageDataGenerator(\n",
    "  data_format=\"channels_last\",\n",
    "  rescale = 1. / 255\n",
    ")\n",
    "\n",
    "validation_batches = validation_generator.flow_from_directory(\n",
    "    batch_size=32,\n",
    "    directory='./dataset/validation',\n",
    "    target_size=(256, 256),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Starts training the model\n",
    "model.fit_generator(train_batches,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch=len(train_batches),\n",
    "                    validation_data=validation_batches,\n",
    "                    initial_epoch=0,\n",
    "                    validation_steps=len(validation_batches)\n",
    "                    )\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_batches = test_generator.flow_from_directory(\n",
    "    batch_size=1,\n",
    "    directory='./dataset/test',\n",
    "    target_size=[256, 256],\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "score = model.evaluate_generator(test_batches, verbose=1)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print('test dataset: ' + str(score))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ResNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential, Model \n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HEIGHT = 300\n",
    "WIDTH = 300\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "class_list = [\"class_1\", \"class_2\"]\n",
    "FC_LAYERS = [1024, 512, 256]\n",
    "dropout = 0.5\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def build_model(base_model, dropout, fc_layers, num_classes):\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    for fc in fc_layers:\n",
    "        print(fc)\n",
    "        x = Dense(fc, activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "    preditions = Dense(num_classes, activation='softmax')(x)\n",
    "    finetune_model = Model(inputs = base_model.input, outputs = preditions)\n",
    "    return finetune_model\n",
    "\n",
    "base_model_1 = ResNet50(weights = 'imagenet',\n",
    "                       include_top = False,\n",
    "                       input_shape = (HEIGHT, WIDTH, 3))\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                   rotation_range = 90,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip = True,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.1,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                  rotation_range = 90,\n",
    "                                  horizontal_flip = True,\n",
    "                                  vertical_flip = False)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size = (HEIGHT, WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                  target_size = (HEIGHT, WIDTH),\n",
    "                                                  batch_size = BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resnet50_model = build_model(base_model_1,\n",
    "                                      dropout = dropout,\n",
    "                                      fc_layers = FC_LAYERS,\n",
    "                                      num_classes = len(class_list))\n",
    "\n",
    "adam = Adam(lr = 0.00001)\n",
    "resnet50_model.compile(adam, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "filepath = \"./checkpoints\" + \"RestNet50\" + \"_model_weights.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor = [\"acc\"], verbose= 1, mode = \"max\")\n",
    "cb=TensorBoard(log_dir=(\"/home/ubuntu/\"))\n",
    "callbacks_list = [checkpoint, cb]\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "resnet50_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = resnet50_model.fit_generator(generator = train_generator, epochs = NUM_EPOCHS, steps_per_epoch = 100, \n",
    "                                       shuffle = True, validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "image_batch,label_batch = train_generator.next()\n",
    "\n",
    "print(len(image_batch))\n",
    "for i in range(0,len(image_batch)):\n",
    "    image = image_batch[i]\n",
    "    print(label_batch[i])\n",
    "    imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inception V3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_2 = InceptionV3(weights = 'imagenet',\n",
    "                       include_top = False,\n",
    "                       input_shape = (HEIGHT, WIDTH, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model = build_model(base_model_2,\n",
    "                                      dropout = dropout,\n",
    "                                      fc_layers = FC_LAYERS,\n",
    "                                      num_classes = len(class_list))\n",
    "inception_model.compile(optimizer = RMSprop(lr = 0.00001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = inception_model.fit_generator(generator = train_generator, epochs = NUM_EPOCHS, steps_per_epoch = 100, \n",
    "                                       shuffle = True, validation_data = test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
